{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from PIL import Image, ImageOps\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "100 33.4M  100 33.4M    0     0  5799k      0  0:00:05  0:00:05 --:--:-- 5602k\n"
     ]
    }
   ],
   "source": [
    "! curl -O https://challenge.blob.core.windows.net/challengefiles/gear_images.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "! tar xopf gear_images.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(arr):\n",
    "    \"\"\"\n",
    "    Linear normalization\n",
    "    http://en.wikipedia.org/wiki/Normalization_%28image_processing%29\n",
    "    \"\"\"\n",
    "    arr = arr.astype('float')\n",
    "    # Do not touch the alpha channel\n",
    "    for i in range(3):\n",
    "        minval = arr[...,i].min()\n",
    "        maxval = arr[...,i].max()\n",
    "        if minval != maxval:\n",
    "            arr[...,i] -= minval\n",
    "            arr[...,i] *= (255/(maxval-minval)) \n",
    "            arr[...,i] += 128\n",
    "    return arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "rawImages = [] \n",
    "labels = []\n",
    "labelMap = {}\n",
    "count = 0\n",
    "size = (128, 128)\n",
    "\n",
    "def list_files(directory,prefix = ''):\n",
    "    global count\n",
    "    for filename in os.listdir(directory):\n",
    "        if  filename.endswith(\".jpeg\") or filename.endswith(\".jpg\") or filename.endswith(\".png\"): \n",
    "            filePath = directory + \"/\" + filename\n",
    "            img = Image.open(filePath)\n",
    "            img.thumbnail(size)\n",
    "            imgResized = Image.new('RGB', size, (0, 0, 0))\n",
    "            imgWidth, imageHeight = img.size\n",
    "            imgResized.paste(img, ((size[0]-imgWidth)//2,(size[1]-imageHeight)//2))\n",
    "            imgArray = normalize(np.array(imgResized))\n",
    "            #np.save(filePath + \".npy\", imgArray)\n",
    "            label = filePath.split(os.path.sep)[-2]\n",
    "            if label not in labelMap.keys():\n",
    "                labelMap[label] = count\n",
    "                label = count\n",
    "                count += 1\n",
    "            else:\n",
    "                label = labelMap[label]\n",
    "            rawImages.append(imgArray)\n",
    "            labels.append([label])\n",
    "                \n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"./gear_images/\" \n",
    "\n",
    "dir_list = os.listdir(path)\n",
    "for p in dir_list:\n",
    "    sub_path = os.path.join(path , p)\n",
    "    list_files(sub_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] label mapping: {'boots': 0, 'hardshell_jackets': 1, 'axes': 2, 'carabiners': 3, 'helmets': 4, 'harnesses': 5, 'rope': 6, 'crampons': 7, 'gloves': 8, 'tents': 9, 'insulated_jackets': 10, 'pulleys': 11} 12\n",
      "[INFO] pixels matrix: 814.85MB\n"
     ]
    }
   ],
   "source": [
    "rawImages = np.array(rawImages) \n",
    "labels = np.array(labels)\n",
    "num_classes = len(labelMap)\n",
    "print(\"[INFO] label mapping:\",labelMap,num_classes)\n",
    "print(\"[INFO] pixels matrix: {:.2f}MB\".format(\n",
    "    rawImages.nbytes / (1024 * 1000.0))) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Activation\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.optimizers import RMSprop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] trainRL Dataset shape [0]\n",
      "[INFO] x_train Dataset shape (1591, 128, 128, 3)\n",
      "[INFO] y_train categorical result shape (1591, 12)\n",
      "[INFO] x_test Dataset shape (531, 128, 128, 3)\n",
      "[INFO] y_test categorical result shape (531, 12)\n"
     ]
    }
   ],
   "source": [
    "(trainRI, testRI, trainRL, testRL) = train_test_split(\n",
    "    rawImages, labels, test_size=0.25, random_state=42)\n",
    "\n",
    "print(\"[INFO] trainRL Dataset shape\",min(trainRL))\n",
    "x_train = trainRI\n",
    "y_train = keras.utils.to_categorical( trainRL , num_classes)\n",
    "x_test = testRI\n",
    "y_test = keras.utils.to_categorical(testRL, num_classes)\n",
    "print(\"[INFO] x_train Dataset shape\",x_train.shape)\n",
    "print(\"[INFO] y_train categorical result shape\",y_train.shape)\n",
    "print(\"[INFO] x_test Dataset shape\",x_test.shape)\n",
    "print(\"[INFO] y_test categorical result shape\",y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] input_shape: (128, 128, 3)\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_24 (Conv2D)           (None, 125, 125, 64)      3136      \n",
      "_________________________________________________________________\n",
      "conv2d_25 (Conv2D)           (None, 122, 122, 64)      65600     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_12 (MaxPooling (None, 61, 61, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_26 (Conv2D)           (None, 58, 58, 128)       131200    \n",
      "_________________________________________________________________\n",
      "conv2d_27 (Conv2D)           (None, 55, 55, 128)       262272    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_13 (MaxPooling (None, 27, 27, 128)       0         \n",
      "_________________________________________________________________\n",
      "flatten_6 (Flatten)          (None, 93312)             0         \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 256)               23888128  \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 12)                3084      \n",
      "=================================================================\n",
      "Total params: 24,353,420\n",
      "Trainable params: 24,353,420\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "input_shape = x_train.shape[1:]\n",
    "print(\"[INFO] input_shape:\",str(input_shape))\n",
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "x_train /= 255\n",
    "x_test /= 255\n",
    "filter_size = (4,4)\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv2D(64, filter_size, activation='relu', input_shape=(128, 128, 3)))\n",
    "model.add(Conv2D(64, filter_size, activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "#model.add(Dropout(0.2))\n",
    "\n",
    "model.add(Conv2D(128, filter_size, activation='relu'))\n",
    "model.add(Conv2D(128, filter_size, activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "#model.add(Dropout(0.2))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(256, activation='relu'))\n",
    "#model.add(Dropout(0.5))\n",
    "model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "# initiate RMSprop optimizer\n",
    "opt = RMSprop(lr=0.0001, decay=1e-6)\n",
    "model.compile(loss='categorical_crossentropy', optimizer=opt, metrics=['accuracy'])\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] x_train Dataset shape (1591, 128, 128, 3)\n",
      "[INFO] y_train categorical result shape (1591, 12)\n",
      "[[0. 0. 1. ... 0. 0. 0.]\n",
      " [0. 1. 0. ... 0. 0. 0.]\n",
      " [0. 1. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "Epoch 1/20\n",
      "1591/1591 [==============================] - 177s 111ms/step - loss: 2.3195 - acc: 0.2690\n",
      "Epoch 2/20\n",
      "1591/1591 [==============================] - 168s 106ms/step - loss: 1.6219 - acc: 0.4613\n",
      "Epoch 3/20\n",
      "1591/1591 [==============================] - 169s 106ms/step - loss: 1.0895 - acc: 0.6524\n",
      "Epoch 4/20\n",
      "1591/1591 [==============================] - 175s 110ms/step - loss: 0.8043 - acc: 0.7241\n",
      "Epoch 5/20\n",
      "1591/1591 [==============================] - 174s 109ms/step - loss: 0.7228 - acc: 0.7561\n",
      "Epoch 6/20\n",
      "1591/1591 [==============================] - 174s 109ms/step - loss: 0.5873 - acc: 0.7913\n",
      "Epoch 7/20\n",
      "1591/1591 [==============================] - 171s 108ms/step - loss: 0.4173 - acc: 0.8586\n",
      "Epoch 8/20\n",
      "1591/1591 [==============================] - 200s 126ms/step - loss: 0.4258 - acc: 0.8567\n",
      "Epoch 9/20\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-29-f7c99d952208>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"[INFO] y_train categorical result shape\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m128\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/anaconda3/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m   1637\u001b[0m           \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1638\u001b[0m           \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1639\u001b[0;31m           validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1640\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1641\u001b[0m   def evaluate(self,\n",
      "\u001b[0;32m/anaconda3/lib/python3.7/site-packages/tensorflow/python/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[0;34m(model, inputs, targets, sample_weights, batch_size, epochs, verbose, callbacks, val_inputs, val_targets, val_sample_weights, shuffle, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[1;32m    213\u001b[0m           \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    214\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 215\u001b[0;31m         \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    216\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    217\u001b[0m           \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.7/site-packages/tensorflow/python/keras/backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2984\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2985\u001b[0m     fetched = self._callable_fn(*array_vals,\n\u001b[0;32m-> 2986\u001b[0;31m                                 run_metadata=self.run_metadata)\n\u001b[0m\u001b[1;32m   2987\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_fetch_callbacks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2988\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.7/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1437\u001b[0m           ret = tf_session.TF_SessionRunCallable(\n\u001b[1;32m   1438\u001b[0m               \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1439\u001b[0;31m               run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1440\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1441\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "print(\"[INFO] x_train Dataset shape\",x_train.shape)\n",
    "print(\"[INFO] y_train categorical result shape\",y_train.shape)\n",
    "print(y_train) \n",
    "model.fit(x_train, y_train, batch_size=128, epochs=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss 0.5345303563299376\n",
      "acc 0.8305084755865194\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(x_test, y_test, verbose=0, batch_size=128)\n",
    "for name,value in zip(model.metrics_names, score):\n",
    "    print(name, value) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_weights('./model_weights.h5')\n",
    "model.save('./model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
